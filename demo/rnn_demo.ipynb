{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:20:45.866560Z",
     "start_time": "2019-06-07T05:20:44.329882Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from RNN.scripts.gen import DataGenerator\n",
    "from RNN.scripts.rnn import singleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the word2token and token2word converters, as well as the embedding matrix converting our tokens to 300-dimensional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:20:46.027286Z",
     "start_time": "2019-06-07T05:20:45.868300Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('word2token.pickle', 'rb') as f:\n",
    "    word2token = pickle.load(f)\n",
    "    \n",
    "with open('token2word.pickle', 'rb') as f:\n",
    "    token2word = pickle.load(f)\n",
    "    \n",
    "with open('embedding_matrix.pickle', 'rb') as f:\n",
    "    embedding_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we import a small demo dataset containing a subset of 1000 samples from the original test set (i.e. not used for training/validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:20:46.040521Z",
     "start_time": "2019-06-07T05:20:46.029712Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('sample_data.pickle', 'rb') as f:\n",
    "    partition = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the example below, the title of each claim and the textual rating of each review is tokenized and the numerical rating is converted to a boolean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:20:46.050212Z",
     "start_time": "2019-06-07T05:20:46.043513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example ID: 88adff73-f7bd-d2e9-b510-a155ce088ba7\n",
      "{'claim': array([   5,  464, 1283,   66, 1122,    3, 7941,  543,    2, 9050, 4828]), 'rating': array([31,  7]), 'isFake': True}\n"
     ]
    }
   ],
   "source": [
    "ID = list(partition['demo'].keys())[1]\n",
    "\n",
    "print('Example ID:', ID)\n",
    "print(partition['demo'][ID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the given claim was evaluated as fake by the original fact checker. We can convert the tokenized values back to their original textual representation to see what the claim and textual ratings were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:20:46.341347Z",
     "start_time": "2019-06-07T05:20:46.333992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim title:\t a single immigrant can bring in unlimited numbers of distant relatives\n",
      "Text rating:\t mostly false\n"
     ]
    }
   ],
   "source": [
    "claim = ' '.join([token2word.get(t) for t in partition['demo'][ID]['claim']])\n",
    "rating = ' '.join([token2word.get(t) for t in partition['demo'][ID]['rating']])\n",
    "\n",
    "print(\"Claim title:\\t\", claim)\n",
    "print(\"Text rating:\\t\", rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then feed all of these data samples to our model by constructing a small data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:20:48.774023Z",
     "start_time": "2019-06-07T05:20:48.770728Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_demo = DataGenerator(partition, mode='demo', all_text=True, train_oov=False, batch_size=1, return_id=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our example batch now contains the tokenized rating description and claim title in combination, and the associated rating value to be predicted as either 1 (indicating the item is fake) or 0 (factually correct):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:20:49.735726Z",
     "start_time": "2019-06-07T05:20:49.731179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      " (array([[  31,    7,    5,  464, 1283,   66, 1122,    3, 7941,  543,    2,\n",
      "        9050, 4828]]), array([[1]]))\n"
     ]
    }
   ],
   "source": [
    "print('Sample batch:\\n', gen_demo.__getitem__(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the pretrained model occupies 273.1 MB, it must be downloaded separately and placed in the demo folder to proceed. The model is made available for download via the following [link](https://drive.google.com/file/d/1SpgTDMaSFUG-cBT3Zh1TZrGU7GFr4HNn/view?usp=sharing).\n",
    "\n",
    "Having downloaded the model, we can now construct the RNN with our pretrained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:21:10.641613Z",
     "start_time": "2019-06-07T05:21:05.822136Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn_single = singleRNN(embedding_matrix)\n",
    "rnn_single.load_weights(\"pretrained_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute the predicted scores and compare them to the true scores (computation may take about a minute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:21:22.554486Z",
     "start_time": "2019-06-07T05:21:11.653260Z"
    }
   },
   "outputs": [],
   "source": [
    "def preds(model, generator):\n",
    "    preds = model.predict_generator(generator)\n",
    "    y_pred = preds.round().astype(int).reshape(len(preds),)\n",
    "    \n",
    "    y_true = np.empty(shape=(len(generator)), dtype=int)    \n",
    "    for i in range(len(generator)):\n",
    "        y_true[i] = generator.__getitem__(i)[1]\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred = preds(rnn_single, gen_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T04:48:32.632939Z",
     "start_time": "2019-06-07T04:48:07.296629Z"
    }
   },
   "source": [
    "So the corresponding accuracy adds up to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-07T05:21:23.724967Z",
     "start_time": "2019-06-07T05:21:23.717420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 94.3%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {0}%\".format(round(sum(y_true == y_pred) / len(y_true), 3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
