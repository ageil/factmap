{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:18:07.951324Z",
     "start_time": "2019-05-11T06:18:05.650625Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anders1991/miniconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from asterixdb.asterixdb import AsterixConnection\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Asterix and get ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:18:07.956309Z",
     "start_time": "2019-05-11T06:18:07.953256Z"
    }
   },
   "outputs": [],
   "source": [
    "con = AsterixConnection(server='http://localhost', port=19002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:18:10.101804Z",
     "start_time": "2019-05-11T06:18:07.958629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25477"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rated = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    SELECT r.*\n",
    "    FROM reviews r\n",
    "    WHERE r.reviewRating.bestRating >= r.reviewRating.ratingValue\n",
    "    AND r.reviewRating.ratingValue >= r.reviewRating.worstRating\n",
    "    AND r.reviewRating.bestRating > r.reviewRating.worstRating;\n",
    "''').results\n",
    "\n",
    "len(rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:18:12.484858Z",
     "start_time": "2019-05-11T06:18:10.105041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34597"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrated = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    SELECT r.*\n",
    "    FROM reviews r\n",
    "    WHERE NOT (r.reviewRating.bestRating >= r.reviewRating.ratingValue\n",
    "    AND r.reviewRating.ratingValue >= r.reviewRating.worstRating\n",
    "    AND r.reviewRating.bestRating > r.reviewRating.worstRating)\n",
    "    OR is_null(r.reviewRating.ratingValue)\n",
    "    OR is_null(r.reviewRating.worstRating)\n",
    "    OR is_null(r.reviewRating.bestRating);\n",
    "''').results\n",
    "\n",
    "len(unrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:18:13.413330Z",
     "start_time": "2019-05-11T06:18:12.487810Z"
    }
   },
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "all_texts = [r['reviewRating']['alternateName'] for r in rated + unrated]\n",
    "t.fit_on_texts(all_texts)\n",
    "\n",
    "vocab_size = len(t.word_index) + 1\n",
    "max_length = max([len(x['reviewRating']['alternateName']) for x in rated + unrated])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:18:13.422827Z",
     "start_time": "2019-05-11T06:18:13.415612Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def word2Vec(word):\n",
    "    try:\n",
    "        vec = con.query('''USE FactMap;\n",
    "            SELECT vector\n",
    "            FROM fasttext f\n",
    "            WHERE f.word = \"{0}\"\n",
    "            ;'''.format(word)).results[0]['vector']\n",
    "        return vec\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:20:01.723592Z",
     "start_time": "2019-05-11T06:18:13.425307Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "embedding_matrix_oov = np.zeros((vocab_size, 300))\n",
    "\n",
    "for word, idx in t.word_index.items():\n",
    "    vec = word2Vec(word)\n",
    "    if vec is not None:\n",
    "        embedding_matrix[idx] = vec\n",
    "    else:\n",
    "        random_vec = [np.random.random(1)[0] for x in range(300)]\n",
    "        embedding_matrix_oov[idx] = random_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:20:01.822691Z",
     "start_time": "2019-05-11T06:20:01.725373Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/anders1991/Github/FactMap/RNN/data/embedding_matrix.pickle', 'wb') as f:\n",
    "    pickle.dump(embedding_matrix, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('/Users/anders1991/Github/FactMap/RNN/data/embedding_matrix_oov.pickle', 'wb') as f:\n",
    "    pickle.dump(embedding_matrix_oov, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:20:01.844751Z",
     "start_time": "2019-05-11T06:20:01.824791Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token <-> word conversion\n",
    "word2token = {w: tk for w, tk in t.word_index.items()}\n",
    "token2word = dict(map(reversed, t.word_index.items()))\n",
    "\n",
    "with open('/Users/anders1991/Github/FactMap/RNN/data/word2token.pickle', 'wb') as f:\n",
    "    pickle.dump(word2token, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('/Users/anders1991/Github/FactMap/RNN/data/token2word.pickle', 'wb') as f:\n",
    "    pickle.dump(token2word, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create {r.uid: tokenized_seq, tokenized_seq_oov, isFake} dicts for both rated and unrated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:20:02.999007Z",
     "start_time": "2019-05-11T06:20:01.847699Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rated_tokenized = t.texts_to_sequences([r['reviewRating']['alternateName'] for r in rated])\n",
    "unrated_tokenized = t.texts_to_sequences([r['reviewRating']['alternateName'] for r in unrated])\n",
    "\n",
    "rated_padded = pad_sequences(rated_tokenized, maxlen=max_length, padding='post')\n",
    "unrated_padded = pad_sequences(unrated_tokenized, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:20:03.043647Z",
     "start_time": "2019-05-11T06:20:03.001170Z"
    }
   },
   "outputs": [],
   "source": [
    "def isFake(r):\n",
    "    \"\"\"Returns True if rating is at most 50%, False otherwise.\"\"\"\n",
    "    bestDiff = r['reviewRating']['bestRating'] - r['reviewRating']['ratingValue']\n",
    "    worstDiff = r['reviewRating']['ratingValue'] - r['reviewRating']['worstRating']\n",
    "    return bestDiff >= worstDiff\n",
    "\n",
    "unrated_ids = [r['uid'] for r in unrated]\n",
    "rated_ids = [r['uid'] for r in rated]\n",
    "rated_isFake = [isFake(r) for r in rated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:20:03.053723Z",
     "start_time": "2019-05-11T06:20:03.046243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isOov(token, embedding_matrix):\n",
    "    \"\"\"Returns True if token is out of vocabulary, False otherwise. Returns None padded values (0).\"\"\"\n",
    "    if token == 0:\n",
    "        return None\n",
    "    elif np.sum(embedding_matrix[token,:]) == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:36:40.946571Z",
     "start_time": "2019-05-11T06:35:55.393218Z"
    }
   },
   "outputs": [],
   "source": [
    "rated_data = dict()\n",
    "for r in zip(rated_ids, rated_padded, rated_isFake):\n",
    "    ID = r[0]\n",
    "    tokenized_desc = np.array([x if not isOov(x, embedding_matrix) else 0 for x in r[1]])\n",
    "    tokenized_desc_oov = np.array([x if isOov(x, embedding_matrix) else 0 for x in r[1]])\n",
    "    isFake = r[2]\n",
    "    rated_data[ID] = ((tokenized_desc, tokenized_desc_oov), isFake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:37:47.310939Z",
     "start_time": "2019-05-11T06:36:41.511968Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unrated_data = dict()\n",
    "for r in zip(unrated_ids, unrated_padded):\n",
    "    ID = r[0]\n",
    "    tokenized_desc = np.array([x if not isOov(x, embedding_matrix) else 0 for x in r[1]])\n",
    "    tokenized_desc_oov = np.array([x if isOov(x, embedding_matrix) else 0 for x in r[1]])\n",
    "    unrated_data[ID] = (tokenized_desc, tokenized_desc_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:37:49.358937Z",
     "start_time": "2019-05-11T06:37:47.312641Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/anders1991/Github/FactMap/RNN/data/data_rated.pickle', 'wb') as f:\n",
    "    pickle.dump(rated_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('/Users/anders1991/Github/FactMap/RNN/data/data_unrated.pickle', 'wb') as f:\n",
    "    pickle.dump(unrated_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:16:34.255324Z",
     "start_time": "2019-05-11T07:16:33.422129Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./data/data_rated.pickle', 'rb') as f:\n",
    "    rated_data = pickle.load(f)\n",
    "\n",
    "with open('./data/data_unrated.pickle', 'rb') as f:\n",
    "    unrated_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:17:08.415438Z",
     "start_time": "2019-05-11T07:17:08.366678Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/embedding_matrix.pickle', 'rb') as f:\n",
    "    embedding_matrix = pickle.load(f)\n",
    "\n",
    "with open('./data/embedding_matrix_oov.pickle', 'rb') as f:\n",
    "    embedding_matrix_oov = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to insert embedding matrices into RNN (lock pretrained embeddings, unlock random out of vocab embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:08:47.718521Z",
     "start_time": "2019-05-11T07:08:41.944757Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.initializers import Constant\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "rnn_in = Input(shape=(max_length,), name='rnn_in')\n",
    "rnn = Embedding(input_dim=vocab_size, \n",
    "                output_dim=300, \n",
    "                input_length=max_length,\n",
    "                weights=[embedding_matrix],\n",
    "                embeddings_initializer=Constant(embedding_matrix),\n",
    "                trainable=False,\n",
    "                mask_zero=True,\n",
    "                name=\"embedding\")(rnn_in)\n",
    "\n",
    "rnn_in_oov = Input(shape=(max_length,), name='rnn_in_oov')\n",
    "rnn_oov = Embedding(input_dim=vocab_size, \n",
    "                    output_dim=300, \n",
    "                    input_length=max_length,\n",
    "                    weights=[embedding_matrix_oov],\n",
    "                    embeddings_initializer=Constant(embedding_matrix_oov),\n",
    "                    trainable=True,\n",
    "                    mask_zero=True,\n",
    "                    name=\"embedding_oov\")(rnn_in_oov)\n",
    "\n",
    "rnn = add([rnn, rnn_oov], name='add')\n",
    "rnn = Bidirectional(LSTM(32, return_sequences=True), name=\"bi_lstm_1\")(rnn)\n",
    "rnn = Bidirectional(LSTM(32, return_sequences=True), name=\"bi_lstm_2\")(rnn)\n",
    "rnn_out = LSTM(1, activation='sigmoid', return_sequences=False, name=\"lstm_out\")(rnn)\n",
    "# rnn_out = Dense(1, activation='sigmoid')(rnn)\n",
    "\n",
    "rnn = Model(inputs=[rnn_in, rnn_in_oov], outputs=rnn_out)\n",
    "\n",
    "rnn.compile(loss='binary_crossentropy',\n",
    "            optimizer=Adam(lr=1e-3),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:08:49.157687Z",
     "start_time": "2019-05-11T07:08:49.149780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rnn_in (InputLayer)             (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rnn_in_oov (InputLayer)         (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 500, 300)     2282100     rnn_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_oov (Embedding)       (None, 500, 300)     2282100     rnn_in_oov[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 500, 300)     0           embedding[0][0]                  \n",
      "                                                                 embedding_oov[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_1 (Bidirectional)       (None, 500, 64)      85248       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_2 (Bidirectional)       (None, 500, 64)      24832       bi_lstm_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_out (LSTM)                 (None, 1)            264         bi_lstm_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,674,544\n",
      "Trainable params: 2,392,444\n",
      "Non-trainable params: 2,282,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:08:54.301443Z",
     "start_time": "2019-05-11T07:08:54.179548Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 354.14 410.00\" width=\"354pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 350.1416,-406 350.1416,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 6466145304 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>6466145304</title>\n",
       "<polygon fill=\"none\" points=\"14.0034,-365.5 14.0034,-401.5 136.1382,-401.5 136.1382,-365.5 14.0034,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75.0708\" y=\"-379.3\">rnn_in: InputLayer</text>\n",
       "</g>\n",
       "<!-- 6466145416 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>6466145416</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 150.1416,-328.5 150.1416,-292.5 0,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75.0708\" y=\"-306.3\">embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 6466145304&#45;&gt;6466145416 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>6466145304-&gt;6466145416</title>\n",
       "<path d=\"M75.0708,-365.4551C75.0708,-357.3828 75.0708,-347.6764 75.0708,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"78.5709,-338.5903 75.0708,-328.5904 71.5709,-338.5904 78.5709,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6466145360 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>6466145360</title>\n",
       "<polygon fill=\"none\" points=\"182.0034,-365.5 182.0034,-401.5 332.1382,-401.5 332.1382,-365.5 182.0034,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.0708\" y=\"-379.3\">rnn_in_oov: InputLayer</text>\n",
       "</g>\n",
       "<!-- 6466145752 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>6466145752</title>\n",
       "<polygon fill=\"none\" points=\"168,-292.5 168,-328.5 346.1416,-328.5 346.1416,-292.5 168,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.0708\" y=\"-306.3\">embedding_oov: Embedding</text>\n",
       "</g>\n",
       "<!-- 6466145360&#45;&gt;6466145752 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>6466145360-&gt;6466145752</title>\n",
       "<path d=\"M257.0708,-365.4551C257.0708,-357.3828 257.0708,-347.6764 257.0708,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"260.5709,-338.5903 257.0708,-328.5904 253.5709,-338.5904 260.5709,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6466145584 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>6466145584</title>\n",
       "<polygon fill=\"none\" points=\"132.5967,-219.5 132.5967,-255.5 199.5449,-255.5 199.5449,-219.5 132.5967,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.0708\" y=\"-233.3\">add: Add</text>\n",
       "</g>\n",
       "<!-- 6466145416&#45;&gt;6466145584 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>6466145416-&gt;6466145584</title>\n",
       "<path d=\"M97.5652,-292.4551C109.0497,-283.2422 123.1878,-271.9006 135.6319,-261.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"137.9096,-264.5779 143.5198,-255.5904 133.5294,-259.1177 137.9096,-264.5779\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6466145752&#45;&gt;6466145584 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>6466145752-&gt;6466145584</title>\n",
       "<path d=\"M234.5764,-292.4551C223.0919,-283.2422 208.9538,-271.9006 196.5097,-261.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"198.6122,-259.1177 188.6218,-255.5904 194.232,-264.5779 198.6122,-259.1177\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6467021400 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>6467021400</title>\n",
       "<polygon fill=\"none\" points=\"39.2759,-146.5 39.2759,-182.5 292.8657,-182.5 292.8657,-146.5 39.2759,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.0708\" y=\"-160.3\">bi_lstm_1(lstm_25): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 6466145584&#45;&gt;6467021400 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>6466145584-&gt;6467021400</title>\n",
       "<path d=\"M166.0708,-219.4551C166.0708,-211.3828 166.0708,-201.6764 166.0708,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"169.5709,-192.5903 166.0708,-182.5904 162.5709,-192.5904 169.5709,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6167764272 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>6167764272</title>\n",
       "<polygon fill=\"none\" points=\"39.2759,-73.5 39.2759,-109.5 292.8657,-109.5 292.8657,-73.5 39.2759,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.0708\" y=\"-87.3\">bi_lstm_2(lstm_26): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 6467021400&#45;&gt;6167764272 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>6467021400-&gt;6167764272</title>\n",
       "<path d=\"M166.0708,-146.4551C166.0708,-138.3828 166.0708,-128.6764 166.0708,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"169.5709,-119.5903 166.0708,-109.5904 162.5709,-119.5904 169.5709,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6213367792 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>6213367792</title>\n",
       "<polygon fill=\"none\" points=\"111.2036,-.5 111.2036,-36.5 220.938,-36.5 220.938,-.5 111.2036,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.0708\" y=\"-14.3\">lstm_out: LSTM</text>\n",
       "</g>\n",
       "<!-- 6167764272&#45;&gt;6213367792 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>6167764272-&gt;6213367792</title>\n",
       "<path d=\"M166.0708,-73.4551C166.0708,-65.3828 166.0708,-55.6764 166.0708,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"169.5709,-46.5903 166.0708,-36.5904 162.5709,-46.5904 169.5709,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(rnn).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle IDs and split into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T06:45:17.798755Z",
     "start_time": "2019-05-11T06:45:17.773354Z"
    }
   },
   "outputs": [],
   "source": [
    "ids = list(rated_data.keys())\n",
    "np.random.seed(2)\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "trainFrac = 0.7\n",
    "validFrac = 0.2\n",
    "\n",
    "partition = dict()\n",
    "partition[\"train\"] = {ID: rated_data[ID] for ID in ids[:int(len(ids)*trainFrac)]}\n",
    "partition[\"valid\"] = {ID: rated_data[ID] for ID in ids[int(len(ids)*trainFrac):int(len(ids)*(trainFrac + validFrac))]}\n",
    "partition[\"test\"] = {ID: rated_data[ID] for ID in ids[int(len(ids)*(trainFrac + validFrac)):]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:21:43.383702Z",
     "start_time": "2019-05-11T07:21:43.344274Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator(partition, mode=\"train\", batch_size=16, predict=False):\n",
    "    X = np.zeros(shape=(batch_size, max_length), dtype=int)\n",
    "    X_oov = X = np.zeros(shape=(batch_size, max_length), dtype=int)\n",
    "    if not predict:\n",
    "        y = np.zeros(shape=(batch_size, 1), dtype=int)\n",
    "    val_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ids = list(partition[mode].keys())\n",
    "        if mode == \"train\":\n",
    "            batch_ids = np.random.choice(ids, batch_size)\n",
    "        elif mode == \"valid\":\n",
    "            batch_ids = ids[val_idx:val_idx+batch_size]  # eval every sample once\n",
    "            val_idx += batch_size\n",
    "        \n",
    "        for i, ID in enumerate(batch_ids):\n",
    "            (seq, seq_oov), tgt = partition[mode][ID]\n",
    "            X[i,:] = seq\n",
    "            X_oov[i,:] = seq_oov\n",
    "            if not predict:\n",
    "                y[i,:] = tgt\n",
    "            \n",
    "            out = [X, X_oov], y if not predict else [X, X_oov]\n",
    "            yield out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and validation data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:21:44.155055Z",
     "start_time": "2019-05-11T07:21:44.147774Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_steps_per_epoch = len(partition['train'].keys()) // batch_size\n",
    "valid_steps_per_epoch = len(partition['valid'].keys()) // batch_size\n",
    "\n",
    "gen_train = generator(partition=partition, mode='train', batch_size=batch_size)\n",
    "gen_valid = generator(partition=partition, mode='valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:21:44.508761Z",
     "start_time": "2019-05-11T07:21:44.498797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 500) (16, 500) (16, 1)\n"
     ]
    }
   ],
   "source": [
    "(X, X_oov), y = gen_train.__next__()\n",
    "print(X.shape, X_oov.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-11T07:26:09.391779Z",
     "start_time": "2019-05-11T07:26:09.388123Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "hist = rnn.fit_generator(generator=gen_train, \n",
    "                         steps_per_epoch=train_steps_per_epoch,\n",
    "                         epochs=n_epochs,\n",
    "                         validation_data=gen_valid,\n",
    "                         validation_steps=valid_steps_per_epoch,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
